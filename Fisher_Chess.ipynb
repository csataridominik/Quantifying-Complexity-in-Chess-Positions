{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from auxiliary_functions import create_position_planes,encode_move\n",
    "import tqdm\n",
    "import chess\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "So the general idea: label positions, based on the next best tactical move.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pieces = {\n",
    "    \"k\": 0,\n",
    "    \"q\": 1,\n",
    "    \"r\": 2,\n",
    "    \"b\": 3,\n",
    "    \"n\": 4,\n",
    "    \"p\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 100000/4211138 [00:53<36:42, 1866.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# This is for labels and data:\n",
    "label_pieces = []\n",
    "label_move_types = []\n",
    "positions = []\n",
    "\n",
    "\n",
    "file_path = r'C:\\Users\\csata\\OneDrive\\Desktop\\FÖT\\Chess_Complexity\\data\\lichess_db_puzzle.csv\\lichess_db_puzzle.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "it = 0\n",
    "\n",
    "tqdm.pandas()\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    if it >= 100000:\n",
    "        break\n",
    "    it += 1\n",
    "\n",
    "    # This part is for creating the 14 planes which reresents the position:\n",
    "    curr_position = row['FEN']\n",
    "    position_planes = create_position_planes(curr_position)\n",
    "    positions.append(position_planes)\n",
    "    # In this part I save the labeles according to the type of movement(plane for direction and distance travelled):\n",
    "    curr_move = row['Moves'].split(' ')[0]\n",
    "    temp_move_plane = encode_move(curr_move)\n",
    "    \n",
    "    #temp_move_types = np.zeros((64,1))\n",
    "    #temp_move_types[temp_move_plane] += 1\n",
    "    label_move_types.append(temp_move_plane)\n",
    "    \n",
    "    # In this part I save the labels according to which piece was moved in the given position:\n",
    "    curr_board = chess.Board(curr_position)\n",
    "    curr_piece = curr_board.piece_at(chess.parse_square(curr_move[:2]))\n",
    "    \n",
    "    #temp_pieces = np.zeros((6,1))\n",
    "    #temp_pieces[pieces[curr_piece.__str__().lower()]] += 1\n",
    "    label_pieces.append(pieces[curr_piece.__str__().lower()])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is result for label_pieces:\n",
      "This is shape of X: (100000, 896)\n",
      "Test accuracy: 0.3585\n",
      "This is result for label_move_types:\n",
      "This is shape of X: (100000, 896)\n",
      "Test accuracy: 0.1638\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def Fisher_train(positions,labels):\n",
    "    \n",
    "    nsamples, nx, ny,nz = positions.shape\n",
    "    X = positions.reshape((nsamples,nx*ny*nz))\n",
    "\n",
    "    print(f'This is shape of X: {X.shape}')\n",
    "\n",
    "    # Split into train/test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Standardize the data (important for LDA)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Apply LDA (Linear Discriminant Analysis) to reduce dimensions and create Fisherfaces-like features\n",
    "    lda = LinearDiscriminantAnalysis(n_components=None)  # None will keep the maximum components\n",
    "    X_train_lda = lda.fit_transform(X_train_scaled, y_train)\n",
    "    X_test_lda = lda.transform(X_test_scaled)\n",
    "\n",
    "    # Use a classifier on the LDA-transformed data\n",
    "    # Let's use an SVM for classification (could use other classifiers like k-NN)\n",
    "    clf = SVC(kernel='linear')\n",
    "    clf.fit(X_train_lda, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = clf.score(X_test_lda, y_test)\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print('This is result for label_pieces:')\n",
    "Fisher_train(np.asarray(positions),np.asarray(label_pieces))\n",
    "\n",
    "print('This is result for label_move_types:')\n",
    "Fisher_train(np.asarray(positions),np.asarray(label_move_types))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is result for label_pieces:\n",
      "Using device: cpu\n",
      "This is shape of X: (100000, 896)\n",
      "Total number of trainable parameters: 624262\n",
      "Epoch 1/20, Loss: 1.7248\n",
      "Test accuracy: 29.8350%\n",
      "Epoch 2/20, Loss: 1.6102\n",
      "Test accuracy: 32.0400%\n",
      "Epoch 3/20, Loss: 1.5273\n",
      "Test accuracy: 34.4900%\n",
      "Epoch 4/20, Loss: 1.4394\n",
      "Test accuracy: 35.6800%\n",
      "Epoch 5/20, Loss: 1.3579\n",
      "Test accuracy: 36.2800%\n",
      "Epoch 6/20, Loss: 1.2658\n",
      "Test accuracy: 36.2650%\n",
      "Epoch 7/20, Loss: 1.1580\n",
      "Test accuracy: 35.5500%\n",
      "Epoch 8/20, Loss: 1.0371\n",
      "Test accuracy: 34.4350%\n",
      "Epoch 9/20, Loss: 0.9085\n",
      "Test accuracy: 34.0150%\n",
      "Epoch 10/20, Loss: 0.7796\n",
      "Test accuracy: 34.9600%\n",
      "Epoch 11/20, Loss: 0.6669\n",
      "Test accuracy: 34.7400%\n",
      "Epoch 12/20, Loss: 0.5635\n",
      "Test accuracy: 33.5550%\n",
      "Epoch 13/20, Loss: 0.4813\n",
      "Test accuracy: 32.9100%\n",
      "Epoch 14/20, Loss: 0.4023\n",
      "Test accuracy: 33.3950%\n",
      "Epoch 15/20, Loss: 0.3490\n",
      "Test accuracy: 33.5350%\n",
      "Epoch 16/20, Loss: 0.3025\n",
      "Test accuracy: 33.3000%\n",
      "Epoch 17/20, Loss: 0.2522\n",
      "Test accuracy: 33.1300%\n",
      "Epoch 18/20, Loss: 0.2192\n",
      "Test accuracy: 32.8800%\n",
      "Epoch 19/20, Loss: 0.1930\n",
      "Test accuracy: 33.6550%\n",
      "Epoch 20/20, Loss: 0.1695\n",
      "Test accuracy: 33.8000%\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 112\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis is result for label_pieces:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 112\u001b[0m label_losses, label_accruacies \u001b[38;5;241m=\u001b[39m Fisher_train(np\u001b[38;5;241m.\u001b[39masarray(positions), np\u001b[38;5;241m.\u001b[39masarray(label_pieces),\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis is result for label_move_types:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    115\u001b[0m move_type_losses, move_type_accuracies \u001b[38;5;241m=\u001b[39m Fisher_train(np\u001b[38;5;241m.\u001b[39masarray(positions), np\u001b[38;5;241m.\u001b[39masarray(label_move_types),\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define a simple neural network (MLP)\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)  \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 256)          \n",
    "        self.fc3 = nn.Linear(256, 128)  \n",
    "        self.fc4 = nn.Linear(128, num_classes)  # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        \n",
    "        x = self.fc4(x)  # No activation on final layer (logits)\n",
    "        return x\n",
    "\n",
    "def Fisher_train(positions, labels,y_type):\n",
    "    train_losses = []\n",
    "    accuracies = []\n",
    "\n",
    "    # Check if GPU is available and use it\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Using device: {device}')\n",
    "\n",
    "    # Reshape data\n",
    "    nsamples, nx, ny, nz = positions.shape\n",
    "    X = positions.reshape((nsamples, nx * ny * nz))\n",
    "\n",
    "    print(f'This is shape of X: {X.shape}')\n",
    "\n",
    "    # Split into train/test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Standardize the data (important for neural networks)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)\n",
    "    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "    # Create datasets and dataloaders\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Define model, loss function, and optimizer\n",
    "    input_size = X_train_scaled.shape[1]  # Number of input features\n",
    "    if y_type:\n",
    "        num_classes = 6  # Number of classes (labels)\n",
    "    else:\n",
    "        num_classes = 64  # Number of classes (labels)\n",
    "\n",
    "    model = SimpleNN(input_size, num_classes).to(device)  # Send model to GPU\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total number of trainable parameters: {total_params}\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()  # For multi-class classification\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 20\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_loader):.4f}\")\n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "\n",
    "        # Evaluation on test set\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                outputs = model(X_batch)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += y_batch.size(0)\n",
    "                correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "        accuracy = correct / total\n",
    "        accuracy = accuracy * 100\n",
    "        print(f\"Test accuracy: {accuracy:.4f}%\")\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "print('This is result for label_pieces:')\n",
    "label_losses, label_accruacies = Fisher_train(np.asarray(positions), np.asarray(label_pieces),True)\n",
    "\n",
    "print('This is result for label_move_types:')\n",
    "move_type_losses, move_type_accuracies = Fisher_train(np.asarray(positions), np.asarray(label_move_types),False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_loss_and_accuracy(losses, accuracies,name=\"training_loss_and_accuracy.png\"):\n",
    "    epochs = range(1, len(losses) + 1)\n",
    "\n",
    "    # Create a figure with two subplots (1 row, 2 columns)\n",
    "    fig, ax1 = plt.subplots(figsize=(10,5))\n",
    "\n",
    "    # Plot Loss\n",
    "    ax1.plot(epochs, losses, 'b-', label='Training Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss', color='b')\n",
    "    ax1.tick_params('y', colors='b')\n",
    "\n",
    "    # Create a twin axis for accuracy\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(epochs, accuracies, 'r-', label='Test Accuracy')\n",
    "    ax2.set_ylabel('Accuracy', color='r')\n",
    "    ax2.tick_params('y', colors='r')\n",
    "\n",
    "    # Add a title\n",
    "    plt.title('Training Loss and Test Accuracy over Epochs')\n",
    "\n",
    "    # Save the figure as a PNG file\n",
    "    plt.savefig(name)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_loss_and_accuracy(label_losses, label_accruacies,name=\"move_types.png\")\n",
    "plot_loss_and_accuracy(move_type_losses, move_type_accuracies,name=\"move_types.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SimpleNN.__init__() missing 2 required positional arguments: 'input_size' and 'num_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount_parameters\u001b[39m(model):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters() \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m total_params \u001b[38;5;241m=\u001b[39m count_parameters(model)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal number of trainable parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: SimpleNN.__init__() missing 2 required positional arguments: 'input_size' and 'num_classes'"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "model = SimpleNN()\n",
    "total_params = count_parameters(model)\n",
    "print(f\"Total number of trainable parameters: {total_params}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
